<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Webscraping Airbnb with scrapy &#8211; </title>
<meta name="description" content="Getting data from Airbnb and do some interesting analysis">
<meta name="keywords" content="tutorial, python, webscraping">


<!-- Twitter Cards -->
<meta name="twitter:title" content="Webscraping Airbnb with scrapy">
<meta name="twitter:description" content="Getting data from Airbnb and do some interesting analysis">
<meta name="twitter:site" content="@alucaria">
<meta name="twitter:creator" content="@alucaria">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="/images/luccaairbnbmap.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Webscraping Airbnb with scrapy">
<meta property="og:description" content="Getting data from Airbnb and do some interesting analysis">
<meta property="og:url" content="/blog/web-scraping-airbnb/">
<meta property="og:site_name" content="">





<link rel="canonical" href="/blog/web-scraping-airbnb/">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<!-- Webfonts -->
<script src="//use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="/assets/js/vendor/html5shiv.min.js"></script>
  <script src="/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">

<!-- pretty print -->





<link rel="stylesheet" href="/assets/css/google-code-prettify/prettify.css">
<script src="/assets/js/google-code-prettify/prettify.js"></script>


</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="/about/" >About</a></li>
		  
		    
		    <li><a href="/blog/" >Blog</a></li>
		  
		    
		    <li><a href="/search/" >Search</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	
		<div class="wrap">
			<a href="/" class="site-logo" rel="home" title=""><img src="/images/LucaASCII.svg" width="200" height="200" alt=" logo" class="animated fadeInDown"></a>
		</div>
	
</header><!-- /.masthead -->


<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    <img src="/images/luccaairbnbmap.png" class="entry-feature-image" alt="Webscraping Airbnb with scrapy" >
    <div class="entry-wrapper">
      <header class="entry-header">
        <span class="entry-tags"><a href="/tags/#tutorial" title="Pages tagged tutorial">tutorial</a>&nbsp;&bull;&nbsp;<a href="/tags/#python" title="Pages tagged python">python</a>&nbsp;&bull;&nbsp;<a href="/tags/#webscraping" title="Pages tagged webscraping">webscraping</a></span>
        
          <h1 class="entry-title">Webscraping Airbnb with scrapy</h1>
        
      </header>
      <footer class="entry-meta">
        
        
          <img src="/images/luca-verginer-8bit.png" class="bio-photo" alt="Luca Verginer bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Luca Verginer</span></span>
        <span class="entry-date date published"><time datetime="2016-02-26T16:18:37+01:00"><i class="fa fa-calendar-o"></i> February 26, 2016</time></span>
        
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        <span class="social-share-twitter">
  <a href="https://twitter.com/intent/tweet?hashtags=tutorial,python,webscraping&amp;text=Webscraping%20Airbnb%20with%20scrapy&amp;url=/blog/web-scraping-airbnb/&amp;via=alucaria" title="Share on Twitter" itemprop="Twitter"><i class="fa fa-twitter-square"></i> Tweet</a>
</span>
<span class="social-share-facebook">
  <a href="https://www.facebook.com/sharer/sharer.php?u=/blog/web-scraping-airbnb/" title="Share on Facebook" itemprop="Facebook"><i class="fa fa-facebook-square"></i> Like</a>
</span>
<span class="social-share-googleplus">
  <a href="https://plus.google.com/share?url=/blog/web-scraping-airbnb/" title="Share on Google Plus" itemprop="GooglePlus"><i class="fa fa-google-plus-square"></i> +1</a>
</span>
<!-- /.social-share -->

        <!-- <div class="google-ads" style="margin-top:40px; text-align:center;">
  <style>
  .responsive-ads { width: 300px; height: 200px; }
  @media(min-width: 518px) { .responsive-ads { width: 468px; height: 60px; } }
  @media(min-width: 778px) { .responsive-ads { width: 728px; height: 90px; } }
  @media(min-width: 1000px) { .responsive-ads { width: 160px; height: 600px; } }
  </style>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <ins class="adsbygoogle responsive-ads"
    style="display:inline-block"
    data-ad-client=""
    data-ad-slot=""></ins>
  <script>
  (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>
-->
<!-- /.google-ads --> <!-- /.google-ads -->
      </footer>
      <div class="entry-content">
        <p>The web is full of wonderful and freely available information. Some of it is readily available and neatly organized (see <a href="https://github.com/caesar0301/awesome-public-datasets">this repo</a>) and some of it is hiding in plain sight. I am speaking about unstructured data on websites, which has either never been organized or the owner does not offer easy access and thus sits there locked away in dusty HTML files.
Some of this wealth of data I am speaking about is publicly available and comes from state of the art databases, but there is no easy way to access it, such as airbnb.com. 
The listings on the Airbnb are freely accessible to anyone who cares to brows their really nice portal, but if we wanted to do some exploratory statistical analysis then there is no easy way to get a complete and sufficiently large dataset. This is where <a href="https://en.wikipedia.org/wiki/Web_scraping">web scraping</a> comes in.</p>

<p>I have always had some questions I wanted to ask airbnb, for example:</p>

<ul>
  <li>How many of their listings are there in my city? (if you check a simple search will never list more than 300 results at a time)</li>
  <li>What is the price distribution?</li>
  <li>Do lots of people leave reviews?</li>
  <li>Is it true that most reviews are positive?</li>
</ul>

<p>I am sure that you can come up with your own set of questions you would like to tickle out of such data. So here I walk you through how to get <em>some</em> of the data, to answer <em>some</em> of these questions.</p>

<p>You can find the complete code <a href="https://github.com/si-tacuisses/bnb_scrapy_tutorial">here as github repo</a>, feel free to fork, clone or do whatever you want with it.</p>

<ul id="markdown-toc">
  <li><a href="#the-plan" id="markdown-toc-the-plan">The Plan</a></li>
  <li><a href="#setting-up-the-system" id="markdown-toc-setting-up-the-system">Setting up the system</a></li>
  <li><a href="#getting-started-with-scrapy" id="markdown-toc-getting-started-with-scrapy">Getting started with Scrapy</a></li>
  <li><a href="#run-the-query" id="markdown-toc-run-the-query">Run the Query</a></li>
  <li><a href="#plot-the-data-on-a-map" id="markdown-toc-plot-the-data-on-a-map">Plot the Data on a Map</a></li>
  <li><a href="#edit" id="markdown-toc-edit">Edit</a></li>
</ul>

<h2 id="the-plan">The Plan</h2>

<p>First we are going to set up the environment to get <a href="scrapy.org">scrapy</a> to work, then write some python code to get our spider to do the tedious task of scraping and after all is said and done we are going explore our hard won dataset.</p>

<h2 id="setting-up-the-system">Setting up the system</h2>

<p>I assume that you have some basic python programming skills and are not intimidate by the command line. We are going to use the python scraping library <a href="scrapy.org">scrapy</a> to do the heavy lifting of routing, scheduling and processing requests.</p>

<p>To install scrapy follow their setup guide for your system, note that scrapy is not compatible with python 3 so make sure that you are using 2.7. Even better if you plan on doing more work in python, and trust me you will, then you should install the great scientific python bundle <a href="https://www.continuum.io/">Anaconda</a>.</p>

<p>Once you are set up, it is time to test drive scrapy. Open a terminal and type:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>scrapy shell http://www.google.com
</code></pre>
</div>

<p>If this does not result in any errors and you are in the <code class="highlighter-rouge">scrapy shell</code> then you are up and running.
Now we set up our project, the scrapy cli interface fortunately creates the basic scaffolding. Navigate using the terminal where you want to save your project, and execute the following commands.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd</span> /path/to/your/location
<span class="gp">$ </span>scrapy startproject bnbtutorial <span class="c"># generate the scrapy scaffolding</span>
<span class="gp">$ </span><span class="nb">cd </span>bnbtutorial <span class="c"># change into directory</span>
<span class="gp">$ </span>scrapy genspider bnbspider airbnb.com <span class="c"># generate a base spider</span>
</code></pre>
</div>

<p>This is the basic setup in the next section we will write the logic of the spider and define what we want it to scrape.</p>

<h2 id="getting-started-with-scrapy">Getting started with Scrapy</h2>

<p>Your project folder should look like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>.
├── bnbtutorial
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       ├── __init__.py
│       └── bnbspider.py
└── scrapy.cfg
</code></pre>
</div>

<p>Open the <code class="highlighter-rouge">bnbspider.py</code> in your favourite editor (e.g. <a href="https://www.jetbrains.com/pycharm/">pycharm</a>)</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">BnbspiderSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"bnbspider"</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">"airbnb.com"</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s">'https://www.airbnb.com/'</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span>
</code></pre>
</div>

<p>Your code will look like this. Every spider class needs to implement the method <code class="highlighter-rouge">parse</code> which takes as argument a http response object from the page(s) found in <code class="highlighter-rouge">start_urls</code>, which we are going to process further. Before we go into the actual data extraction phase we need to get some information from a potential results page. If we run a query and obtain a list of results we want to know how many pages there are. To do this, we add the following method to our <code class="highlighter-rouge">BnbspiderSpider</code> class.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">last_pagenumer_in_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>  <span class="c"># to get the last page number </span>
        <span class="n">last_page_number</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">response</span>
                               <span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//ul[@class="list-unstyled"]/li[last()-1]/a/@href'</span><span class="p">)</span>
                               <span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                               <span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'page='</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                               <span class="p">)</span>
        <span class="k">return</span> <span class="n">last_page_number</span>

    <span class="k">except</span> <span class="nb">IndexError</span><span class="p">:</span>  <span class="c"># if there is no page number</span>
        <span class="c"># get the reason from the page</span>
        <span class="n">reason</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//p[@class="text-lead"]/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="c"># and if it contains the key words set last page equal to 0</span>
        <span class="k">if</span> <span class="n">reason</span> <span class="ow">and</span> <span class="p">(</span><span class="s">'find any results that matched your criteria'</span> <span class="ow">in</span> <span class="n">reason</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="s">'No results on page'</span> <span class="o">+</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
        <span class="c"># otherwise we can conclude that the page </span>
        <span class="c"># has results but that there is only one page.</span>
            <span class="k">return</span> <span class="mi">1</span>
</code></pre>
</div>

<p>This function extracts from a results page the last page number using <code class="highlighter-rouge">xpath</code> queries. If you are not familiar with <code class="highlighter-rouge">xpath</code>, look at the <a href="http://www.w3schools.com/xsl/xpath_intro.asp">w3 tutorial</a>.</p>

<p>With this information we can then create a list of pages using the following format to go from one page to the next.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>https://www.airbnb.com/s/Lucca--Italy?page=&lt;page_number&gt;
</code></pre>
</div>

<p>Add the following lines to <code class="highlighter-rouge">bnbspider.py</code></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="c"># ge the last page number on the page</span>
    <span class="n">last_page_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_pagenumer_in_search</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">last_page_number</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c"># abort the search if there are no results</span>
        <span class="k">return</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c"># otherwise loop over all pages and scrape!</span>
        <span class="n">page_urls</span> <span class="o">=</span> <span class="p">[</span><span class="n">response</span><span class="o">.</span><span class="n">url</span> <span class="o">+</span> <span class="s">"?page="</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pageNumber</span><span class="p">)</span>
                 <span class="k">for</span> <span class="n">pageNumber</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_page_number</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">page_url</span> <span class="ow">in</span> <span class="n">page_urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">page_url</span><span class="p">,</span> 
                                <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_listing_results_page</span><span class="p">)</span>
</code></pre>
</div>

<p>Before we can move to the data extraction phase, we need to get the unique listings url from the results page using the following method.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">parse_listing_results_page</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">href</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="listing"]/@data-url'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
        <span class="c"># get all href of the speficied kind and join them to be a valid url</span>
        <span class="n">url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">href</span><span class="p">)</span>
        <span class="c"># request the url and pass the response to final listings parsing function</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_listing_contents</span><span class="p">)</span>
</code></pre>
</div>

<p>Now to the interesting part, extracting the data. I have writte the <code class="highlighter-rouge">xpath</code> to extract some of the data from the page which in this case is hidden in a <code class="highlighter-rouge">json</code>file. This is a minimal example and there is a lot more information, to get (i.e. geographic coordinates). The scrapy documentation has a nice primer on how to use the developer tools found in Firefox/Chrome to create <code class="highlighter-rouge">xpath</code> expressions and some other general tips.
Thi is the centrepiece of the class, the function which extracts the data and stores it in a scrapy object, which we are going to define shortely.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">parse_listing_contents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">item</span> <span class="o">=</span> <span class="n">BnbtutorialItem</span><span class="p">()</span>

    <span class="n">json_array</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//meta[@id="_bootstrap-room_options"]/@content'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">json_array</span><span class="p">:</span>
        <span class="n">airbnb_json_all</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json_array</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">airbnb_json</span> <span class="o">=</span> <span class="n">airbnb_json_all</span><span class="p">[</span><span class="s">'airEventData'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'rev_count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'visible_review_count'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'amenities'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'amenities'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'host_id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json_all</span><span class="p">[</span><span class="s">'hostId'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'hosting_id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'hosting_id'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'room_type'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'room_type'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'bed_type'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'bed_type'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'person_capacity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'person_capacity'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'cancel_policy'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'cancel_policy'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'rating_communication'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'communication_rating'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'rating_cleanliness'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'cleanliness_rating'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'rating_checkin'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'checkin_rating'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'satisfaction_guest'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'guest_satisfaction_overall'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'instant_book'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'instant_book_possible'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'accuracy_rating'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'accuracy_rating'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'response_time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'response_time_shown'</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'response_rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json</span><span class="p">[</span><span class="s">'reponse_rate_shown'</span><span class="p">]</span>   
        <span class="n">item</span><span class="p">[</span><span class="s">'nightly_price'</span><span class="p">]</span> <span class="o">=</span> <span class="n">airbnb_json_all</span><span class="p">[</span><span class="s">'nightly_price'</span><span class="p">]</span>
    <span class="n">item</span><span class="p">[</span><span class="s">'url'</span><span class="p">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span>
    <span class="k">yield</span> <span class="n">item</span>
</code></pre>
</div>

<p>note that this function uses the <code class="highlighter-rouge">json</code> library so be sure to import it <code class="highlighter-rouge">import json</code>.</p>

<p>Now to the last step, we need to define a <code class="highlighter-rouge">scrapy.Item</code> class, to store the scraped info to. Open the file <code class="highlighter-rouge">items.py</code> and create all the fields which we are going to need.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">BnbtutorialItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="n">rev_count</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">amenities</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">host_id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">hosting_id</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">room_type</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">price</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">bed_type</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">person_capacity</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">cancel_policy</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">rating_communication</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">rating_cleanliness</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">rating_checkin</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">satisfaction_guest</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">instant_book</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">accuracy_rating</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">response_time</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">response_rate</span>  <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">nightly_price</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</code></pre>
</div>

<p>Be sure to import <code class="highlighter-rouge">BnbtutorialItem</code> in the <code class="highlighter-rouge">BnbSpider</code>, by adding <code class="highlighter-rouge">from bnbtutorial.items import BnbtutorialItem</code> to the top of of the <code class="highlighter-rouge">bnbspider.py</code> file, as well as adding to the function <code class="highlighter-rouge">parse_listing_contents</code> at the beginning <code class="highlighter-rouge">item = BnbtutorialItem()</code>. After these changes the spider script should look something like this,</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">bnbtutorial.items</span> <span class="kn">import</span> <span class="n">BnbtutorialItem</span> <span class="c"># &lt;--- import here!</span>

<span class="n">QUERY</span> <span class="o">=</span> <span class="s">'Lucca--Italy'</span>

<span class="k">class</span> <span class="nc">BnbSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"bnbspider"</span>
<span class="c"># .....</span>
<span class="c"># LEFT OUT SOME CODE  SAME AS IN THE PREVIOUS PART</span>
<span class="c"># .....</span>
    <span class="k">def</span> <span class="nf">parse_listing_contents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">BnbtutorialItem</span><span class="p">()</span>  <span class="c"># &lt;--- user the Item here!</span>

        <span class="n">json_array</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//meta[@id="_bootstrap-room_options"]/@content'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="c"># ....</span>
<span class="c"># REST OF FILE AS BEFORE </span>
</code></pre>
</div>

<h2 id="run-the-query">Run the Query</h2>

<p>Now to run your own query for your city simply edit the variable <code class="highlighter-rouge">QUERY</code> at the top of the script, which takes most often the following form <code class="highlighter-rouge">City--Country</code> a quick check by running the query on airbnb will reveal.</p>

<p>As good netizens there are a few things we need to keep in mind when scraping a website. As far I know it isn’t illegal to scrap a website, starting a <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack">DDoS</a> attack on the other hand is, so to avoid any ambiguity in what you are doing, you should throttle the speed at which you scrape. For Airbnb I have found that it is best not to go above the limit of 8 pages per minute, or your IP will be banned.  To enable the throttling in scrapy you need to uncomment the following lines in <code class="highlighter-rouge">settings.py</code> . If you need more speed, you might want to look into renting some amazon AWS machines (micro instances are pretty cheap).</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">USER_AGENT</span> <span class="o">=</span> <span class="s">'bnbtutorial (+http://www.yourdomain.com)'</span>
<span class="n">CONCURRENT_REQUESTS_PER_DOMAIN</span><span class="o">=</span><span class="mi">10</span>
<span class="n">AUTOTHROTTLE_ENABLED</span><span class="o">=</span><span class="bp">True</span>
<span class="c"># The initial download delay</span>
<span class="n">AUTOTHROTTLE_START_DELAY</span><span class="o">=</span><span class="mi">5</span>
<span class="c"># The maximum download delay to be set in case of high latencies</span>
<span class="n">AUTOTHROTTLE_MAX_DELAY</span><span class="o">=</span><span class="mi">60</span>
<span class="c"># Enable showing throttling stats for every response received:</span>
<span class="n">AUTOTHROTTLE_DEBUG</span><span class="o">=</span><span class="bp">False</span>
</code></pre>
</div>

<p>And now for the main event, running the spider and see how it all works (hopefully). Run the following command inside your scrapy project and see the data flow in.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>scrapy crawl bnbspider -o LuccaAirbnb.csv
</code></pre>
</div>

<p>As I have already anticipated earlier this is a very basic spider to crawl airbnb. You will see that it will never return more than 300 results at a time and that some records will be duplicates. It is then left to you to find ways to circumvent this limit and avoid calls to urls that have already been scraped (hint: use filters to fine-grain your queries and look at the scrapy documentation on how to avoid duplicate requests.)</p>

<h2 id="plot-the-data-on-a-map">Plot the Data on a Map</h2>

<p>The listings contain also longitude and latitude information (which we did not get here, but you can get it easily if you have a look at the <code class="highlighter-rouge">head</code> of any listings page).
We can use this data to visualize the distribution and concentration of properties on a map.</p>

<p><img src="/images/luccaairbnbmap.png" alt="Airbnb Properties in Lucca and their Concentration" title="Airbnb properties in Lucca" /></p>

<h2 id="edit">Edit</h2>

<ul>
  <li>added instructions on how to change city in the query</li>
</ul>


        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'MatEcon'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="/blog/vietnamese-snake-puzzle/" class="btn" title="Vietnamese Snake Puzzle">Previous</a>
      
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    
<!-- <span>&copy; 2016 Luca Verginer. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/so-simple/" rel="nofollow">So Simple Theme</a>.</span> -->
<div class="social-icons">
    
    	<a href="http://twitter.com/alucaria" title="Luca Verginer on Twitter" target="_blank"><i class="fa fa-twitter-square fa-2x"></i></a>
    
    
    
    
    <a href="si-tacuisses" title="Luca Verginer on StackExchange" target="_blank"><i class="fa fa-stack-exchange fa-2x"></i></a>
    
    
    <a href="http://github.com/si-tacuisses" title="Luca Verginer on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
    
    
    
    <a href="https://bitbucket.org/alucaria" title="Luca Verginer on Bitbucket" target="_blank"><i class="fa fa-bitbucket-square fa-2x"></i></a>
    <a href="/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a>
</div>
<!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = '';
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl = 
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-5673135-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'stats.g.doubleclick.net/dc.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



<script type="text/javascript">
    $(document).ready(function(){
    // Add the class of pre requried by Google Code Prettify
    $('pre').addClass('prettyprint');
    $('pre').addClass('lang-mma');
    prettyPrint()
});
</script>



</body>
</html>
